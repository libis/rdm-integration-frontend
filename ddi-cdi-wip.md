### Summary (Oct 25, 2025)
- Environment: backend lives in `/home/eryk/projects/rdm-integration` (Dataverse + integration Go service); frontend is this repo (`rdm-integration-frontend`).
- Typical commands: backend `make dev_up` (brings up docker stack) / `make dev_down`; frontend `npm run test -- --watch=false`, `make fmt`, `make lint`, `ng serve` (via repo script if needed).
- Current state: DDI-CDI Angular tests now pass after spec fixes providing valid Turtle fixtures; SHACL warnings cleared after replacing placeholder Turtle in mocks.
- CDI cache: `tests/response.json` / `tests/response.ttl` now show merged output from multiple csv_to_cdi runs; headerless files promoted row values (e.g., salaries, names) to `cdi:Variable`, so the graph leaks record-level data instead of staying metadata-only.
- Upload issue: earlier uploads sent only Turtle prefixes and triggered a 500 with Go JSON decode error (`AddReplaceFileResponse.message` expects string, backend returns object when upload fails). The frontend now merges SHACL edits back into the full CDI Turtle before upload; need to re-test the Dataverse call and still harden response handling.
- Outstanding UI work: SHACL form error handling (see TODO below).
- SHACL tooling view: ULB Darmstadt’s generic SHACL form component renders fields directly from a SHACL shape graph; it’s viable once we ship full CDI-aligned shapes but currently stalls because we lack a stable root node shape. Without those shapes the renderer can’t reflect our UX or validation needs, so custom Angular forms may serve better until shapes are in place.
- SHACL shape graph research: official DDI Lifecycle SHACL exports live in the `ddimodel` GitHub releases, but no ready-made CDI-specific shapes turned up—available CDI assets are RDF encodings in the `ddi-cdi` repo/spec, so we’d need to derive shapes ourselves or adapt lifecycle ones.

### Concepts refresher
- **Turtle (TTL)** is the compact syntax we use to serialize RDF triples; our generator emits CDI dataset descriptions in this format.
- **RDF vocabularies** like CDI define the predicates/classes (e.g., `cdi:Variable`, `dcterms:title`) that give the TTL meaning.
- **SHACL** is the constraint language layered on RDF; shapes describe what properties/structures should exist and power validation or auto-generated forms. A SHACL form renderer needs both the shape graph (rules) and the data graph (our CDI TTL) to work.

### TODO
- [x] Move the dataset selection dropdown out of the sticky menu and mirror the download component (label, layout, styles).
- [x] Relocate the `Generate DDI-CDI` button into the right sticky menu and reuse the download component iconography.
- [x] Replace the "Select" header text in the tree table with a toggleable checkmark matching the download component behaviour (supports select/deselect all).
- [x] Investigate and resolve `Error: shacl root node shape not found`, using the captured `response.json` from `/api/common/cachedddicdioutput` to build tests/mocks.
- [x] Ensure `Add to Dataset` always uploads clean Turtle output even when the SHACL editor fails to render.
- [x] Wire the SHACL form integration to emit full CDI Turtle (not just prefixes) before invoking upload.
- [ ] Confirm the SHACL form renders without errors for valid CDI output; currently blocked because the cached CDI Turtle treats row values as `cdi:Variable` resources, so the renderer cannot bind column-level shapes.
- [ ] Diagnose the HTTP 500 when calling `api/datasets/:persistentId/add` (`json: cannot unmarshal object into ... AddReplaceFileResponse.message`); verify the request payload with the merged Turtle and align the response handling with backend expectations.
- [ ] Host the SHACL shapes we design on the backend alongside the embedded frontend config (`Dockerfile`, `frontend.go` `go:embed all:dist/datasync`).
- [ ] Improve `image/csv_to_cdi.py` so each run emits column-level variables only (handle headerless tables, avoid per-row logical datasets, dedupe roles) before merging into cached CDI.
- [ ] Document SHACL shape hosting/contribution guidance in `ddi-cdi.md`, mirroring how `csv_to_cdi.py` participation is covered.
- [ ] Restrict `xconvert` usage to cases where `GetDataFileDDI` returns no output during the `cdi_ddi.go` job execution path.
- [ ] Extend `image/test_csv_to_cdi.py` to parse and assert against the `testdata/tmp_ddi8.xml` output generated by `GetDataFileDDI`.

### Progress
- Angular unit suite now green after updating `src/app/ddi-cdi/ddi-cdi.component.spec.ts` with valid Turtle fixtures and richer DOM mocks; rerun via `npm run test -- --watch=false`.
- Upload attempt previously failed server-side with 500 due to response message type mismatch; with the new Turtle merge helper the upload payload now includes the full dataset graph—pending verification against the real Dataverse API.
- DDI-CDI layout now mirrors the download component (dropdown placement, sticky action button, select-all icon); validated via `make test`.
- Cached response-driven regression tests cover SHACL root shape detection, unedited Turtle uploads, and merged SHACL edits; added in `src/app/ddi-cdi/ddi-cdi.component.spec.ts` and verified via `npm run test -- --watch=false`.
- Implemented Turtle merge helpers in `src/app/ddi-cdi/ddi-cdi.component.ts` so SHACL form submissions rehydrate the original graph, preserve prefixes, and keep uploads in sync with user edits.
- Replaced placeholder Turtle strings in SHACL-related mocks with valid CDI dataset snippets to eliminate parser warnings during tests.
- Analysis of `tests/response.json` / `tests/response.ttl` shows only the first logical dataset defines true column metadata; subsequent nodes expose row values (`score`, `95_5`, `John_Doe`, etc.) as variables after csv_to_cdi treated the first data row as headers, so SHACL forms fail until the generator separates structure from data and we supply matching shapes.

### Next Steps
- Reproduce and trace the add-file 500 in integration logs now that uploads send merged Turtle; confirm expected response schema and adjust request handling or backend client accordingly.
- Normalize the CDI generator so columns emit as `cdi:Variable` definitions while record-level values remain in the physical dataset payload, then retest the SHACL form with a hosted shape graph that covers those variables.
### Notes
- Keep the prompt reusable: add new discoveries or regressions to the checklist above.
- When work completes on any item, flip the checkbox and reference supporting commits/tests.
- Plan carefully and execute step-by-step.

### Notes about the csv_to_cdi.py script

- response.ttl models the dataset DOI 10.5072/FK2/HWBVZM as a cdi:DataSet, links nine blank-node cdi:LogicalDataSet entries, and declares every cdi:Variable/cdi:Role pair the generator has ever seen for that dataset. The first logical dataset lists the expected column variables (AGE, INCOME, etc.), while the other eight correspond to single records (e.g., the tuple 1, 2020-01-15, 35, 75000.50, John Doe, true)—those row values show up because they were treated as “column names” when the CSV lacked a header.
- The file also inlines every Dataverse tabular file as a separate cdi:PhysicalDataSet, embedding either the harvested DDI Codebook XML literals or the 400 error payloads when a file was not ingested. The prov:wasGeneratedBy list repeats the same cdi:ProcessStep blank node for each invocation, another hint that multiple file-level runs were merged without deduplicating blank nodes.
- Comparing with csv_to_cdi.py: the script streams one CSV, infers per-column stats, emits exactly one logical dataset, and never tries to encode row-level cells. That matches the pipeline description in rdm-integration/ddi-cdi.md (“constructs a DDI-CDI compliant RDF graph… describes each variable with its properties and relationships”). The only way to get the extra logical datasets and “variables” like #var/95_5 is if it was run repeatedly—once per data file—and, for headerless files such as sample_no_header.tab, the first data row was mistaken for the header (because the tool default is header=True). Those mistaken column names propagate into the merged graph.
- So the current response.ttl only partially matches the documented intent: it does carry dataset-level and per-file metadata, but it also exposes specific dataset values (IDs, salaries, names, dates, booleans) as skos:prefLabels on cdi:Variables. In other words, it is not strictly metadata; some individual data points have leaked into what should be purely structural descriptions.